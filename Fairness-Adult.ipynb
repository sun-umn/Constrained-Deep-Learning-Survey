{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4258ce-b448-4e6d-8b74-fe2ed91bed68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ryandevera/data-science/umn_environments/Constrained-Deep-Learning-Survey'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1956e81c-2397-40d8-b7ec-d6dfad14dbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 14:02:45.760884: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# stdlib\n",
    "import math\n",
    "import random\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_constrained_optimization as tfco\n",
    "import warnings\n",
    "\n",
    "# first party\n",
    "from cdlsurvey.data import get_data\n",
    "from cdlsurvey.models import Model\n",
    "from cdlsurvey.utils import training_helper\n",
    "\n",
    "# Disable eager execution\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "# suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For plotting in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6eade18-286d-4de4-8419-6830c335443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTECTED_COLUMNS = ['gender_Female', 'gender_Male', 'race_White', 'race_Black']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0181c8b-6878-4ff4-bcb7-eb73585692bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\n",
    "    'workclass', 'education', 'marital_status', 'occupation', 'relationship',\n",
    "    'race', 'gender', 'native_country'\n",
    "]\n",
    "CONTINUOUS_COLUMNS = [\n",
    "    'age', 'capital_gain', 'capital_loss', 'hours_per_week', 'education_num'\n",
    "]\n",
    "COLUMNS = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "    'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
    "    'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "    'income_bracket'\n",
    "]\n",
    "LABEL_COLUMN = 'label'\n",
    "\n",
    "PROTECTED_COLUMNS = [\n",
    "    'gender_Female', 'gender_Male', 'race_White', 'race_Black'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6367c64-5261-4b32-acf6-08f83e49cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the data\n",
    "train_df, test_df, FEATURE_NAMES = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c780842-7bdd-4e8a-b6b2-f12efc88a107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7841, 3846)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure there are positive labels\n",
    "train_df['label'].sum(), test_df['label'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e159c7c-4c35-4bb9-8aed-fc51cafc8b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def training_generator(model,\n",
    "#                        train_df,\n",
    "#                        test_df,\n",
    "#                        minibatch_size,\n",
    "#                        num_iterations_per_loop=1,\n",
    "#                        num_loops=1):\n",
    "#     random.seed(31337)\n",
    "#     num_rows = train_df.shape[0]\n",
    "#     minibatch_size = min(minibatch_size, num_rows)\n",
    "#     permutation = list(range(train_df.shape[0]))\n",
    "#     random.shuffle(permutation)\n",
    "\n",
    "#     session = tf.Session()\n",
    "#     session.run((tf.global_variables_initializer(),\n",
    "#                tf.local_variables_initializer()))\n",
    "\n",
    "#     minibatch_start_index = 0\n",
    "#     for n in range(num_loops):\n",
    "#         for _ in range(num_iterations_per_loop):\n",
    "#             minibatch_indices = []\n",
    "#             while len(minibatch_indices) < minibatch_size:\n",
    "#                 minibatch_end_index = (\n",
    "#                 minibatch_start_index + minibatch_size - len(minibatch_indices))\n",
    "#                 if minibatch_end_index >= num_rows:\n",
    "#                     minibatch_indices += range(minibatch_start_index, num_rows)\n",
    "#                     minibatch_start_index = 0\n",
    "#                 else:\n",
    "#                     minibatch_indices += range(minibatch_start_index, minibatch_end_index)\n",
    "#                     minibatch_start_index = minibatch_end_index\n",
    "                    \n",
    "#             session.run(\n",
    "#                   model.train_op,\n",
    "#                   feed_dict=model.feed_dict_helper(\n",
    "#                       train_df.iloc[[permutation[ii] for ii in minibatch_indices]]))\n",
    "\n",
    "#         train_predictions = session.run(\n",
    "#             model.predictions_tensor,\n",
    "#             feed_dict=model.feed_dict_helper(train_df))\n",
    "#         test_predictions = session.run(\n",
    "#             model.predictions_tensor,\n",
    "#             feed_dict=model.feed_dict_helper(test_df))\n",
    "\n",
    "#         yield (train_predictions, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673ef15c-7f52-4d8a-bf76-8b402e490fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def error_rate(predictions, labels):\n",
    "#     signed_labels = (\n",
    "#       (labels > 0).astype(np.float32) - (labels <= 0).astype(np.float32))\n",
    "#     numerator = (np.multiply(signed_labels.values, predictions.values) <= 0).sum()\n",
    "#     denominator = predictions.shape[0]\n",
    "#     return float(numerator) / float(denominator)\n",
    "\n",
    "\n",
    "# def positive_prediction_rate(predictions, subset):\n",
    "#     numerator = np.multiply((predictions > 0).astype(np.float32),\n",
    "#                           (subset > 0).astype(np.float32)).sum()\n",
    "#     denominator = (subset > 0).sum()\n",
    "#     return float(numerator) / float(denominator)\n",
    "\n",
    "# def tpr(df):\n",
    "#     \"\"\"Measure the true positive rate.\"\"\"\n",
    "#     fp = sum((df['predictions'] >= 0.0) & (df[LABEL_COLUMN] > 0.5))\n",
    "#     ln = sum(df[LABEL_COLUMN] > 0.5)\n",
    "#     return float(fp) / float(ln)\n",
    "\n",
    "# def _get_error_rate_and_constraints(df, tpr_max_diff):\n",
    "#     \"\"\"Computes the error and fairness violations.\"\"\"\n",
    "#     error_rate_local = error_rate(df[['predictions']], df[[LABEL_COLUMN]])\n",
    "#     overall_tpr = tpr(df)\n",
    "#     return error_rate_local, [(overall_tpr - tpr_max_diff) - tpr(df[df[protected_attribute] > 0.5]) for protected_attribute in PROTECTED_COLUMNS]\n",
    "\n",
    "# def _get_exp_error_rate_constraints(cand_dist, error_rates_vector, constraints_matrix):\n",
    "#     \"\"\"Computes the expected error and fairness violations on a randomized solution.\"\"\"\n",
    "#     expected_error_rate = np.dot(cand_dist, error_rates_vector)\n",
    "#     expected_constraints = np.matmul(cand_dist, constraints_matrix)\n",
    "#     return expected_error_rate, expected_constraints\n",
    "\n",
    "# def training_helper(model,\n",
    "#                     train_df,\n",
    "#                     test_df,\n",
    "#                     minibatch_size,\n",
    "#                     num_iterations_per_loop=1,\n",
    "#                     num_loops=1):\n",
    "#     train_error_rate_vector = []\n",
    "#     train_constraints_matrix = []\n",
    "#     test_error_rate_vector = []\n",
    "#     test_constraints_matrix = []\n",
    "#     for train, test in training_generator(\n",
    "#       model, train_df, test_df, minibatch_size, num_iterations_per_loop,\n",
    "#       num_loops):\n",
    "#         train_df['predictions'] = train\n",
    "#         test_df['predictions'] = test\n",
    "\n",
    "#         train_error_rate, train_constraints = _get_error_rate_and_constraints(\n",
    "#           train_df, model.tpr_max_diff)\n",
    "#         train_error_rate_vector.append(train_error_rate)\n",
    "#         train_constraints_matrix.append(train_constraints)\n",
    "\n",
    "#         test_error_rate, test_constraints = _get_error_rate_and_constraints(\n",
    "#             test_df, model.tpr_max_diff)\n",
    "#         test_error_rate_vector.append(test_error_rate)\n",
    "#         test_constraints_matrix.append(test_constraints)\n",
    "\n",
    "#     return (train_error_rate_vector, train_constraints_matrix, test_error_rate_vector, test_constraints_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c6ff35-0de3-4163-afb7-aa4a525d494d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mbuild_train_op(\u001b[38;5;241m0.01\u001b[39m, unconstrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# training_helper returns the list of errors and violations over each epoch.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m train_errors, train_violations, test_errors, test_violations \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_iterations_per_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m326\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_loops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data-science/umn_environments/Constrained-Deep-Learning-Survey/cdlsurvey/utils.py:95\u001b[0m, in \u001b[0;36mtraining_helper\u001b[0;34m(model, train_df, test_df, minibatch_size, num_iterations_per_loop, num_loops)\u001b[0m\n\u001b[1;32m     92\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Compute the error rate and contraints for train\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m train_error_rate, train_constraints \u001b[38;5;241m=\u001b[39m \u001b[43m_get_error_rate_and_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtpr_max_diff\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m train_error_rate_vector\u001b[38;5;241m.\u001b[39mappend(train_error_rate)\n\u001b[1;32m     99\u001b[0m train_constraints_matrix\u001b[38;5;241m.\u001b[39mappend(train_constraints)\n",
      "File \u001b[0;32m~/data-science/umn_environments/Constrained-Deep-Learning-Survey/cdlsurvey/metrics.py:40\u001b[0m, in \u001b[0;36m_get_error_rate_and_constraints\u001b[0;34m(df, tpr_max_diff)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_error_rate_and_constraints\u001b[39m(df, tpr_max_diff):\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    Computes the error and fairness violations.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     error_rate_local \u001b[38;5;241m=\u001b[39m \u001b[43merror_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredictions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLABEL_COLUMN\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     overall_tpr \u001b[38;5;241m=\u001b[39m tpr(df)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m error_rate_local, [\n\u001b[1;32m     43\u001b[0m         (overall_tpr \u001b[38;5;241m-\u001b[39m tpr_max_diff) \u001b[38;5;241m-\u001b[39m tpr(df[df[protected_attribute] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m])\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m protected_attribute \u001b[38;5;129;01min\u001b[39;00m PROTECTED_COLUMNS\n\u001b[1;32m     45\u001b[0m     ]\n",
      "File \u001b[0;32m~/data-science/umn_environments/Constrained-Deep-Learning-Survey/cdlsurvey/metrics.py:19\u001b[0m, in \u001b[0;36merror_rate\u001b[0;34m(labels, predictions)\u001b[0m\n\u001b[1;32m     14\u001b[0m signed_labels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     15\u001b[0m     (labels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m-\u001b[39m (labels \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Assign the numerator\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m numerator \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mmultiply(\u001b[43msigned_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m, predictions\u001b[38;5;241m.\u001b[39mvalues) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Assign the denominator\u001b[39;00m\n\u001b[1;32m     22\u001b[0m denominator \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    tpr_max_diff=0.05,\n",
    "    protected_columns=PROTECTED_COLUMNS,\n",
    "    feature_names=FEATURE_NAMES,\n",
    "    label_column=LABEL_COLUMN,\n",
    ")\n",
    "model.build_train_op(0.01, unconstrained=True)\n",
    "\n",
    "# training_helper returns the list of errors and violations over each epoch.\n",
    "train_errors, train_violations, test_errors, test_violations = training_helper(\n",
    "      model,\n",
    "      train_df,\n",
    "      test_df,\n",
    "      100,\n",
    "      num_iterations_per_loop=326,\n",
    "      num_loops=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6111fb18-1172-45ee-a548-ca2760623566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/ryandevera/data-science/umn_environments/Constrained-Deep-Learning-Survey/cdlsurvey/metrics.py\u001b[0m(19)\u001b[0;36merror_rate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     17 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m    \u001b[0;31m# Assign the numerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 19 \u001b[0;31m    \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigned_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m    \u001b[0;31m# Assign the denominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  signed_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(       predictions\n",
      "0             -1.0\n",
      "1              1.0\n",
      "2             -1.0\n",
      "3             -1.0\n",
      "4              1.0\n",
      "...            ...\n",
      "32556         -1.0\n",
      "32557         -1.0\n",
      "32558         -1.0\n",
      "32559         -1.0\n",
      "32560          1.0\n",
      "\n",
      "[32561 rows x 1 columns],)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  type(signed_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a518c-fe36-4a6b-9136-9f0c49f5d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Error\", train_errors[-1])\n",
    "print(\"Train Violation\", max(train_violations[-1]))\n",
    "print()\n",
    "print(\"Test Error\", test_errors[-1])\n",
    "print(\"Test Violation\", max(test_violations[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ae740-2fa0-41b0-88d9-2f1d2280203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    tpr_max_diff=0.05,\n",
    "    protected_columns=PROTECTED_COLUMNS,\n",
    "    feature_names=FEATURE_NAMES,\n",
    "    label_column=LABEL_COLUMN,\n",
    ")\n",
    "model.build_train_op(0.01, unconstrained=False)\n",
    "\n",
    "# training_helper returns the list of errors and violations over each epoch.\n",
    "train_errors, train_violations, test_errors, test_violations = training_helper(\n",
    "      model,\n",
    "      train_df,\n",
    "      test_df,\n",
    "      100,\n",
    "      num_iterations_per_loop=326,\n",
    "      num_loops=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55c114-91e1-4639-a4fd-d1843574b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Error\", train_errors[-1])\n",
    "print(\"Train Violation\", max(train_violations[-1]))\n",
    "print()\n",
    "print(\"Test Error\", test_errors[-1])\n",
    "print(\"Test Violation\", max(test_violations[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7689ccc-aaa1-41f2-abea-6849b04512a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Error\", np.mean(train_errors))\n",
    "print(\"Train Violation\", max(np.mean(train_violations, axis=0)))\n",
    "print()\n",
    "print(\"Test Error\", np.mean(test_errors))\n",
    "print(\"Test Violation\", max(np.mean(test_violations, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777d432-237f-4a46-a7c5-01e1aa162a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_dist = tfco.find_best_candidate_distribution(train_errors, train_violations)\n",
    "print(cand_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a0c3a-8322-49ac-9a97-624f69f4f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_stoch_error_train, m_stoch_violations_train = _get_exp_error_rate_constraints(cand_dist, train_errors, train_violations)\n",
    "m_stoch_error_test, m_stoch_violations_test = _get_exp_error_rate_constraints(cand_dist, test_errors, test_violations)\n",
    "\n",
    "print(\"Train Error\", m_stoch_error_train)\n",
    "print(\"Train Violation\", max(m_stoch_violations_train))\n",
    "print()\n",
    "print(\"Test Error\", m_stoch_error_test)\n",
    "print(\"Test Violation\", max(m_stoch_violations_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b770a83-599a-4a00-8363-e9ef9105a4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa2c40-dbf1-4ff7-85d3-6ec59c0a3f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdl-survey",
   "language": "python",
   "name": "cdl-survey"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
