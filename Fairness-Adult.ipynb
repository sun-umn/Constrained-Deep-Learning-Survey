{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4258ce-b448-4e6d-8b74-fe2ed91bed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956e81c-2397-40d8-b7ec-d6dfad14dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import math\n",
    "import random\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_constrained_optimization as tfco\n",
    "import warnings\n",
    "\n",
    "# first party\n",
    "from cdlsurvey.data import get_data\n",
    "\n",
    "# Disable eager execution\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "# suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For plotting in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eade18-286d-4de4-8419-6830c335443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTECTED_COLUMNS = ['gender_Female', 'gender_Male', 'race_White', 'race_Black']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0181c8b-6878-4ff4-bcb7-eb73585692bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, FEATURE_NAMES = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6367c64-5261-4b32-acf6-08f83e49cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9904b498-ac80-4683-87a6-3e3e2741a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self,\n",
    "                 tpr_max_diff=0):\n",
    "        tf.random.set_random_seed(123)\n",
    "        self.tpr_max_diff = tpr_max_diff\n",
    "        num_features = len(FEATURE_NAMES)\n",
    "        self.features_placeholder = tf.placeholder(\n",
    "            tf.float32, shape=(None, num_features), name='features_placeholder')\n",
    "        self.labels_placeholder = tf.placeholder(\n",
    "            tf.float32, shape=(None, 1), name='labels_placeholder')\n",
    "        self.protected_placeholders = [tf.placeholder(tf.float32, shape=(None, 1), name=attribute+\"_placeholder\") for attribute in PROTECTED_COLUMNS]\n",
    "        # We use a linear model.\n",
    "        self.predictions_tensor = tf.layers.dense(inputs=self.features_placeholder, units=1, activation=None)\n",
    "\n",
    "\n",
    "    def build_train_op(self,\n",
    "                       learning_rate,\n",
    "                       unconstrained=False):\n",
    "        ctx = tfco.rate_context(self.predictions_tensor, self.labels_placeholder)\n",
    "        positive_slice = ctx.subset(self.labels_placeholder > 0) \n",
    "        overall_tpr = tfco.positive_prediction_rate(positive_slice)\n",
    "        constraints = []\n",
    "        if not unconstrained:\n",
    "            for placeholder in self.protected_placeholders:\n",
    "                slice_tpr = tfco.positive_prediction_rate(ctx.subset((placeholder > 0) & (self.labels_placeholder > 0)))\n",
    "                constraints.append(slice_tpr >= overall_tpr - self.tpr_max_diff)\n",
    "        mp = tfco.RateMinimizationProblem(tfco.error_rate(ctx), constraints)\n",
    "        opt = tfco.ProxyLagrangianOptimizerV1(tf.train.AdamOptimizer(learning_rate))\n",
    "        self.train_op = opt.minimize(mp)\n",
    "\n",
    "        import pdb; pdb.set_trace()\n",
    "        return self.train_op\n",
    "  \n",
    "    def feed_dict_helper(self, dataframe):\n",
    "        feed_dict = {self.features_placeholder:\n",
    "                  dataframe[FEATURE_NAMES],\n",
    "              self.labels_placeholder:\n",
    "                  dataframe[[LABEL_COLUMN]],}\n",
    "        for i, protected_attribute in enumerate(PROTECTED_COLUMNS):\n",
    "            feed_dict[self.protected_placeholders[i]] = dataframe[[protected_attribute]]\n",
    "        return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e159c7c-4c35-4bb9-8aed-fc51cafc8b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_generator(model,\n",
    "                       train_df,\n",
    "                       test_df,\n",
    "                       minibatch_size,\n",
    "                       num_iterations_per_loop=1,\n",
    "                       num_loops=1):\n",
    "    random.seed(31337)\n",
    "    num_rows = train_df.shape[0]\n",
    "    minibatch_size = min(minibatch_size, num_rows)\n",
    "    permutation = list(range(train_df.shape[0]))\n",
    "    random.shuffle(permutation)\n",
    "\n",
    "    session = tf.Session()\n",
    "    session.run((tf.global_variables_initializer(),\n",
    "               tf.local_variables_initializer()))\n",
    "\n",
    "    minibatch_start_index = 0\n",
    "    for n in range(num_loops):\n",
    "        for _ in range(num_iterations_per_loop):\n",
    "            minibatch_indices = []\n",
    "            while len(minibatch_indices) < minibatch_size:\n",
    "                minibatch_end_index = (\n",
    "                minibatch_start_index + minibatch_size - len(minibatch_indices))\n",
    "                if minibatch_end_index >= num_rows:\n",
    "                    minibatch_indices += range(minibatch_start_index, num_rows)\n",
    "                    minibatch_start_index = 0\n",
    "                else:\n",
    "                    minibatch_indices += range(minibatch_start_index, minibatch_end_index)\n",
    "                    minibatch_start_index = minibatch_end_index\n",
    "                    \n",
    "            session.run(\n",
    "                  model.train_op,\n",
    "                  feed_dict=model.feed_dict_helper(\n",
    "                      train_df.iloc[[permutation[ii] for ii in minibatch_indices]]))\n",
    "\n",
    "        train_predictions = session.run(\n",
    "            model.predictions_tensor,\n",
    "            feed_dict=model.feed_dict_helper(train_df))\n",
    "        test_predictions = session.run(\n",
    "            model.predictions_tensor,\n",
    "            feed_dict=model.feed_dict_helper(test_df))\n",
    "\n",
    "        yield (train_predictions, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ef15c-7f52-4d8a-bf76-8b402e490fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(predictions, labels):\n",
    "    signed_labels = (\n",
    "      (labels > 0).astype(np.float32) - (labels <= 0).astype(np.float32))\n",
    "    numerator = (np.multiply(signed_labels.values, predictions.values) <= 0).sum()\n",
    "    denominator = predictions.shape[0]\n",
    "    return float(numerator) / float(denominator)\n",
    "\n",
    "\n",
    "def positive_prediction_rate(predictions, subset):\n",
    "    numerator = np.multiply((predictions > 0).astype(np.float32),\n",
    "                          (subset > 0).astype(np.float32)).sum()\n",
    "    denominator = (subset > 0).sum()\n",
    "    return float(numerator) / float(denominator)\n",
    "\n",
    "def tpr(df):\n",
    "    \"\"\"Measure the true positive rate.\"\"\"\n",
    "    fp = sum((df['predictions'] >= 0.0) & (df[LABEL_COLUMN] > 0.5))\n",
    "    ln = sum(df[LABEL_COLUMN] > 0.5)\n",
    "    return float(fp) / float(ln)\n",
    "\n",
    "def _get_error_rate_and_constraints(df, tpr_max_diff):\n",
    "    \"\"\"Computes the error and fairness violations.\"\"\"\n",
    "    error_rate_local = error_rate(df[['predictions']], df[[LABEL_COLUMN]])\n",
    "    overall_tpr = tpr(df)\n",
    "    return error_rate_local, [(overall_tpr - tpr_max_diff) - tpr(df[df[protected_attribute] > 0.5]) for protected_attribute in PROTECTED_COLUMNS]\n",
    "\n",
    "def _get_exp_error_rate_constraints(cand_dist, error_rates_vector, constraints_matrix):\n",
    "    \"\"\"Computes the expected error and fairness violations on a randomized solution.\"\"\"\n",
    "    expected_error_rate = np.dot(cand_dist, error_rates_vector)\n",
    "    expected_constraints = np.matmul(cand_dist, constraints_matrix)\n",
    "    return expected_error_rate, expected_constraints\n",
    "\n",
    "def training_helper(model,\n",
    "                    train_df,\n",
    "                    test_df,\n",
    "                    minibatch_size,\n",
    "                    num_iterations_per_loop=1,\n",
    "                    num_loops=1):\n",
    "    train_error_rate_vector = []\n",
    "    train_constraints_matrix = []\n",
    "    test_error_rate_vector = []\n",
    "    test_constraints_matrix = []\n",
    "    for train, test in training_generator(\n",
    "      model, train_df, test_df, minibatch_size, num_iterations_per_loop,\n",
    "      num_loops):\n",
    "        train_df['predictions'] = train\n",
    "        test_df['predictions'] = test\n",
    "\n",
    "        train_error_rate, train_constraints = _get_error_rate_and_constraints(\n",
    "          train_df, model.tpr_max_diff)\n",
    "        train_error_rate_vector.append(train_error_rate)\n",
    "        train_constraints_matrix.append(train_constraints)\n",
    "\n",
    "        test_error_rate, test_constraints = _get_error_rate_and_constraints(\n",
    "            test_df, model.tpr_max_diff)\n",
    "        test_error_rate_vector.append(test_error_rate)\n",
    "        test_constraints_matrix.append(test_constraints)\n",
    "\n",
    "    return (train_error_rate_vector, train_constraints_matrix, test_error_rate_vector, test_constraints_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6ff35-0de3-4163-afb7-aa4a525d494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(tpr_max_diff=0.05)\n",
    "model.build_train_op(0.01, unconstrained=True)\n",
    "\n",
    "# training_helper returns the list of errors and violations over each epoch.\n",
    "train_errors, train_violations, test_errors, test_violations = training_helper(\n",
    "      model,\n",
    "      train_df,\n",
    "      test_df,\n",
    "      100,\n",
    "      num_iterations_per_loop=326,\n",
    "      num_loops=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a518c-fe36-4a6b-9136-9f0c49f5d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Error\", train_errors[-1])\n",
    "print(\"Train Violation\", max(train_violations[-1]))\n",
    "print()\n",
    "print(\"Test Error\", test_errors[-1])\n",
    "print(\"Test Violation\", max(test_violations[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ae740-2fa0-41b0-88d9-2f1d2280203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(tpr_max_diff=0.05)\n",
    "model.build_train_op(0.01, unconstrained=False)\n",
    "\n",
    "# training_helper returns the list of errors and violations over each epoch.\n",
    "train_errors, train_violations, test_errors, test_violations = training_helper(\n",
    "      model,\n",
    "      train_df,\n",
    "      test_df,\n",
    "      100,\n",
    "      num_iterations_per_loop=326,\n",
    "      num_loops=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55c114-91e1-4639-a4fd-d1843574b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Error\", train_errors[-1])\n",
    "print(\"Train Violation\", max(train_violations[-1]))\n",
    "print()\n",
    "print(\"Test Error\", test_errors[-1])\n",
    "print(\"Test Violation\", max(test_violations[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7689ccc-aaa1-41f2-abea-6849b04512a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Error\", np.mean(train_errors))\n",
    "print(\"Train Violation\", max(np.mean(train_violations, axis=0)))\n",
    "print()\n",
    "print(\"Test Error\", np.mean(test_errors))\n",
    "print(\"Test Violation\", max(np.mean(test_violations, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777d432-237f-4a46-a7c5-01e1aa162a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_dist = tfco.find_best_candidate_distribution(train_errors, train_violations)\n",
    "print(cand_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a0c3a-8322-49ac-9a97-624f69f4f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_stoch_error_train, m_stoch_violations_train = _get_exp_error_rate_constraints(cand_dist, train_errors, train_violations)\n",
    "m_stoch_error_test, m_stoch_violations_test = _get_exp_error_rate_constraints(cand_dist, test_errors, test_violations)\n",
    "\n",
    "print(\"Train Error\", m_stoch_error_train)\n",
    "print(\"Train Violation\", max(m_stoch_violations_train))\n",
    "print()\n",
    "print(\"Test Error\", m_stoch_error_test)\n",
    "print(\"Test Violation\", max(m_stoch_violations_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c9071-50a8-45fb-8eb9-151144426842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdl-survey",
   "language": "python",
   "name": "cdl-survey"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
